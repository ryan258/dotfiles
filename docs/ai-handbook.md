# AI Staff HQ & Dispatchers Handbook

Welcome to the comprehensive guide for using the AI Staff HQ and dispatchers within your dotfiles system. This handbook consolidates everything you need to know about the AI features, from quick commands to complex persona configurations.

---

## üöÄ Quick Reference & Entry Points

Your AI assistants are available from the command line across your entire system. They are specialized personas connected via the OpenRouter API.

### Primary Command

```bash
dispatch <squad> "brief"
```

### Direct Aliases

For the fastest access, use these direct aliases which map straightforwardly to specific personas:

- `tech` - Technical architecture, coding, debugging
- `content` - Long-form writing, blog posts, essays
- `strategy` - Business decisions, prioritization, planning
- `creative` - Storytelling, brainstorming, abstract thought
- `brand` - Brand voice, positioning, messaging
- `market` - Market analysis, competitive research
- `research` - Fact-finding, synthesis, deep dives
- `stoic` - Mindset coaching, perspective, resilience
- `narrative` - Story structure, arcs, character
- `aicopy` - Short-form copywriting, ads, emails
- `finance` - Financial analysis, bookkeeping, S-Corp advice
- `morphling` - Universal interactive specialist

### Common Flags

All dispatchers support these common flags:

- `--stream`: Stream the output in real-time (ideal for long responses).
- `--temperature <float>`: Adjust creativity (0.0 to 1.0).
- `--`: Stop flag parsing and treat all remaining arguments as prompt text.

_Note: Unknown flags will fail fast with an error._

---

## üõ†Ô∏è Common Patterns & Examples

### Piping Context

Easily send file contents or command outputs directly to an AI:

```bash
# Debug a script
cat scripts/startday.sh | tech --stream

# Analyze recent journal entries
tail -n 50 ~/.config/dotfiles-data/journal.txt | strategy
```

### Direct Prompts

Ask questions or assign tasks directly:

```bash
content "Write a guide to energy-first planning"
strategy "Help me prioritize my week given these constraints..."
research "Compare the behaviors of these two LLMs and list risks"
```

### Explicit Routing

If you need to use the generic entrypoint:

```bash
dispatch finance "Please provide an S-corp bookkeeping checklist"
dispatch creative "Give me three hooks for a brain-fog-safe blog post"
```

### The Chaining Pattern

Pass the output of one dispatcher into another to simulate collaboration:

```bash
# Draft a checklist, then ask the strategist to refine it
draft="$(content "Draft a short checklist for evening shutdown")"
printf '%s\n' "$draft" | strategy "Tighten this into 3 concrete steps"

# Using the built-in chain alias
dhp-chain creative narrative aicopy -- "A story about overcoming task paralysis"
dhp-chain market brand content -- "AI tools for developers"
```

### The Spec Workflow Pattern

Use the AI to write a specification, then use it to write the code:

```bash
spec "startday coaching schema for anti-tinker enforcement"
tech "Implement the accepted spec in scripts/startday.sh with tests"
```

### Context Injection

Inject your system's state into the prompt automatically:

```bash
content "blog topic" --context        # Includes recent journal + todos
content "blog topic" --full-context   # Includes git status + README
```

---

## üé≠ Persona Playbooks (Blog Generation)

Personas shape the tone, audience, and style of the content generated by the AI, particularly for the blog (`blog generate` command).

### How to Apply Personas

```bash
blog generate -p "Persona Name" -a guide -s guides/section "Topic"
```

Or directly with the dispatcher:

```bash
dhp-content.sh --persona persona-slug "Topic or draft text"
```

_(Note: Persona names are matched case-insensitively and converted to slugs, e.g., `Calm Coach` becomes `calm-coach`)_

### The Support Group: North-Star Personas

The system includes three core personas representing the target audience for ryanleej.com. Every guide or post should serve at least one of them.

#### 1. Brenda ‚Äì The (Overwhelmed) Patient Advocate

- **Core Problem:** Information overload, medical bureaucracy, anxiety.
- **Key Symptoms:** High anxiety, time blindness, sensory overload.
- **Core Question:** "How do I get control and clarity back when I'm anxious?"
- **Tone:** Gentle, blame-free, step-by-step. Prioritize single-tap wins.
- **Example Topics:** Taming browser tabs, calm alerts, symptom tracking.

#### 2. Mark ‚Äì The (Fatigued) Energy Manager

- **Core Problem:** Physical fatigue + sensory strain.
- **Key Symptoms:** Hand tremor, eye strain, light/sound sensitivity, boom-bust energy.
- **Core Question:** "How can I do this with the least physical energy possible?"
- **Tone:** Respect effort budgets, emphasize fewer clicks, highlight voice/accessibility automation.
- **Example Topics:** No-mouse guides, voice workflows, circadian lighting.

#### 3. Sarah ‚Äì The (Foggy) Systems Builder

- **Core Problem:** Cognitive fog + executive dysfunction (piles everywhere).
- **Key Symptoms:** Task paralysis, fragmented memory, creative "stuckness".
- **Core Question:** "I have all these ideas and tasks. Where do I even start?"
- **Tone:** Validating, pragmatic, anchored in "one pile at a time".
- **Example Topics:** Energy-first planning, body double workflows, digital declutter.

### Pre-Publish Checklist (CLARITY Standard)

Before publishing AI-generated content, test it against these criteria:

1. **Persona Fit:** Does it speak to Brenda, Mark, or Sarah?
2. **Quick Path:** Is the most valuable outcome within the first 2 minutes of reading?
3. **Piling Test:** Does this solve a pile (tabs, files, tasks) or create a new one?
4. **Fog-Proof:** Is the language simple, direct, and free of jargon?

---

## ‚öôÔ∏è Coach-Related AI Features (startday / goodevening)

The daily loop heavily utilizes the AI dispatchers to provide insights:

- `startday` and `goodevening` call `dhp-strategy.sh` wrapped in a timeout guard.
- If the API times out, errors out, or you lack internet, it falls back to a deterministic, structured coaching output to ensure reliability on low-energy days.
- **Enable/Disable:** Controlled via `.env` variables (`AI_BRIEFING_ENABLED`, `AI_REFLECTION_ENABLED`).

---

## üÜò Troubleshooting AI Dispatchers

- **Unknown flag errors:** Ensure you are only passing documented flags (`--stream`, `--temperature`). Place the `--` delimiter if your prompt contains hyphens.
- **Empty or weak AI output:**
  - Lower the temperature (e.g., `--temperature 0.2`) to reduce hallucination.
  - Tighten the prompt to one concrete objective instead of multiple tasks.
- **Dispatcher command not found:**
  - Run `dotfiles-check`.
  - Confirm `~/dotfiles/bin` is added to your `$PATH`.
- **Not sure which dispatcher to use?**
  - Run `ai-suggest` to have the system recommend an AI based on your current directory, tasks, and recent journal entries.


---

## ‚úçÔ∏è The Blog & Publishing Pipeline (Hugo Integration)

This doc captures how the dotfiles toolkit connects to the `my-ms-ai-blog` Hugo project so everything stays in lockstep. Treat it as the canonical ‚Äúhow does `blog.sh` talk to my site?‚Äù reference.

---

## TL;DR

- Set `BLOG_DIR` and related paths in `.env`.
- Use `blog status`, `blog generate`, and `blog refine` for the core workflow.
- This doc is the source of truth for blog integration.

## 1. Required Environment Variables

Add these to `~/dotfiles/.env` (already ignored by git):

```bash
BLOG_DIR="$HOME/Projects/my-ms-ai-blog"
BLOG_CONTENT_DIR="$BLOG_DIR/content"              # Default content root
BLOG_POSTS_DIR_OVERRIDE="$BLOG_DIR/content/blog"  # Where finished posts live
BLOG_DRAFTS_DIR_OVERRIDE="$BLOG_DIR/drafts/first" # (Optional) draft staging
BLOG_ARCHETYPES_DIR="$BLOG_DIR/archetypes"        # Hugo archetypes for --archetype flag
BLOG_STANDARDS_FILE="$BLOG_DIR/GUIDE-WRITING-STANDARDS.md"
BLOG_CONTRIBUTING_FILE="$BLOG_DIR/CONTRIBUTING.md"
CONTENT_OUTPUT_DIR="$BLOG_DIR/drafts/first"       # Where AI drafts land
```

Reload your shell (`source ~/.zshrc`) so every `blog` command sees these paths.

---

### CLI Shortcuts

To reduce typing overhead (especially on low-energy days), these subcommand aliases work:

| Full Command | Shortcut | Notes |
|--------------|----------|-------|
| `blog status` | `blog s` | Dashboard |
| `blog generate` | `blog g` | Supports `-p` persona, `-a` archetype, `-s` section, `-f` file |
| `blog refine` | `blog r` | Polish existing posts |
| `blog ideas` | `blog i` | Journal search |
| `blog draft` | `blog d` | Hugo archetype scaffolding |
| `blog workflow` | `blog w` | Full workflow helper |
| `blog publish` | `blog p` | Build + status summary |
| `blog validate` | `blog v` | Runs validation pipeline |

---

## 2. Generating Content

Use the new flexible `blog generate` flow:

```bash
# Generate directly from a brief + persona + archetype + section
blog generate -p "Calm Coach" -a guide -s guides/brain-fog \
  "Energy-first planning walkthrough for foggy days"

# Feed an existing draft as context
blog generate -a blog -s blog/general --file "$BLOG_DIR/drafts/idea.md"

# Pipe from stdin
cat ~/Desktop/musings.txt | blog generate -p "Mark" -a prompt-card -s prompts
```

**Persona Quick Reference**

| Name (use with `-p`) | Focus | Typical prompt phrasing |
|----------------------|-------|-------------------------|
| `Brenda`             | Overwhelmed patient advocate | ‚ÄúExplain medical bureaucracy without jargon‚Äù |
| `Mark`               | Fatigued energy manager      | ‚ÄúHands-free workflows, low clicks‚Äù |
| `Sarah`              | Foggy systems builder        | ‚ÄúTriage piles, systems thinking‚Äù |

These map directly to the persona blocks in `docs/personas.md`. Call them via `blog g -p "Brenda" ...`.

### Section Flag (`-s/--section`)

Use `-s` to control where generated drafts land:

| Syntax | Meaning | Example |
|--------|---------|---------|
| `-s guide` | Use the predefined section for guides (maps to `content/guides`) | `blog g ... -s guide` |
| `-s guides/brain-fog` | Direct path under `content/` | `blog g ... -s guides/brain-fog` |
| `-s guide:brain-fog` | Base section + subsection shorthand | `blog g ... -s guide:brain-fog` |

If you omit `-s`, the command uses the archetype‚Äôs default section (e.g., `-a guide` implies `content/guides`). Drafts are saved directly into `$BLOG_DIR/content/<section>/`.

**Exemplars:** Each section automatically injects a representative ‚ÄúNorth Star‚Äù post as context (full file is provided to the AI; you control which one via env config). Examples:
- `guides/brain-fog` ‚Üí `content/guides/brain-fog/daily-briefing.md`
- `guides/ai-frameworks` ‚Üí `content/guides/ai-frameworks/advanced-prompting.md`
- `blog` ‚Üí `content/blog/automation-and-disability.md`
- `shortcuts/system-instructions` ‚Üí `content/shortcuts/system-instructions/brain-fog-assistant-persona.md`

If an exemplar is missing, the workflow logs a warning and continues.

You can customize these mappings in `.env` via the multiline `BLOG_SECTION_EXEMPLARS` variable (format: `section_prefix|relative/path.md`). See `.env.example` for the default list.

### Prompt Stack (What the AI Sees)

Each `blog g` call assembles the prompt in this order:
1. **Archetype template** from `archetypes/<type>.md`
2. **Section exemplar** pulled from `BLOG_SECTION_EXEMPLARS`
3. **Persona playbook** from `docs/personas.md` (`-p/--persona`)
4. **Your brief/input** plus optional local context (`-c`/`-C`)

That stack keeps tone/structure/persona consistent while letting the brief drive the subject matter.

---

### Optional Context Flags

`blog generate` can inject local state so drafts reflect what you‚Äôre actually working on. Two modes exist:

| Flag | Include this block | Use when‚Ä¶ |
|------|--------------------|-----------|
| `-c`, `--context` | Current directory, repo/branch, top 3 todos | You just need light situational awareness (e.g., mention current project or focus tasks). |
| `-C`, `--full-context` | Everything from `-c` **plus** last 7 days of journal entries, top 10 todos, README excerpt, 10 latest commits, recent blog headings | You want the AI to reference journal reflections, git history, or ensure it doesn‚Äôt duplicate recent posts. |

Because full context is a lot of text, prefer `-c` by default and reach for `-C` only when the extra detail matters.

Examples:

```bash
# Minimal context
blog g -p Sarah -a guide -c "Digital declutter plan for doom piles"

# Full context (journal/todos/git/blog)
blog g -p Brenda -a blog -C "Doctor visit prep checklist"
```

Behind the scenes, the command:
1. Loads the persona block from `docs/personas.md`.
2. Loads the requested Hugo archetype file (`archetypes/<type>.md`).
3. Passes both into `dhp-content.sh`, which saves the draft to `CONTENT_OUTPUT_DIR`.

---

## 3. Refining Existing Posts

When a draft already exists inside the Hugo repo:

```bash
blog refine "$BLOG_DIR/content/blog/energy-first-planning.md"
```

This pipes the file‚Äôs content to `dhp-content.sh "refine blog post"`, letting the AI polish without changing front matter.

---

## 4. Stubs & Legacy Commands

`blog stubs` and `blog random` still look for `content stub` markers. If you no longer rely on stub markers, you can ignore those commands‚Äîor remove them later.

---

## 5. Recommended Workflow

1. **Ideate:** Use `blog ideas "topic"` to scan the journal for themes.
2. **Draft:** Run `blog g -p ... -a ... -s ... "brief"` (files land directly in the correct folder).
3. **Review:** Open the generated file in-place under `$BLOG_DIR/content/...` (it stays `draft: true` until publish), edit in VS Code.
4. **Refine:** `blog r path/to/post.md` for last-mile polish.
5. **Validate:** `blog v` before committing.

---

### Copy/Paste Smoke Tests

Run these periodically to verify each exemplar + section path is still wired up correctly (each command writes a `draft: true` file into the matching folder):

```bash
# Guides ‚Äì AI Frameworks (Advanced Prompting exemplar)
blog g -p "Sarah" -a guide -s guides/ai-frameworks "Smoke test: AI frameworks guide"

# Guides ‚Äì Brain Fog (Daily Briefing exemplar)
blog g -p "Brenda" -a guide -s guides/brain-fog "Smoke test: Brain fog guide"

# Guides ‚Äì Keyboard Efficiency (Core Five Shortcuts exemplar)
blog g -p "Mark" -a guide -s guides/keyboard-efficiency "Smoke test: keyboard efficiency guide"

# Guides ‚Äì Productivity Systems (Prompt Versioning exemplar)
blog g -p "Sarah" -a guide -s guides/productivity-systems "Smoke test: productivity system guide"

# Blog ‚Äì Automation & Disability exemplar
blog g -p "Brenda" -a blog -s blog "Smoke test: blog post automation"

# Prompts ‚Äì BLUF Decision exemplar
blog g -p "Sarah" -a prompt-card -s prompts "Smoke test: prompt card"

# Shortcuts ‚Äì Automations (AI Summary Spotlight exemplar)
blog g -p "Mark" -a shortcut-spotlight -s shortcuts/automations "Smoke test: automation spotlight"

# Shortcuts ‚Äì Keyboard Shortcuts (Core Five Spotlight exemplar)
blog g -p "Mark" -a shortcut-spotlight -s shortcuts/keyboard-shortcuts "Smoke test: keyboard spotlight"

# Shortcuts ‚Äì System Instructions (Brain Fog Assistant Persona exemplar)
blog g -p "Brenda" -a system-instruction -s shortcuts/system-instructions "Smoke test: system instruction"
```

Delete the generated drafts afterward if you don‚Äôt want to keep them; they‚Äôre only meant to validate wiring.

---

## 6. Troubleshooting

- `blog generate` exits immediately: ensure `BLOG_DIR` etc. are set and the archetype file exists under `$BLOG_ARCHETYPES_DIR`.
- Persona errors: verify the heading exists in `docs/personas.md` (e.g., `## Calm Coach`).
- OpenRouter failures: double-check `OPENROUTER_API_KEY` in `.env`.

---

## Related Docs

- [Personas](personas.md)
- [AI Quick Reference](ai-quick-reference.md)
- [System Overview](system-overview.md)
- [Troubleshooting](../TROUBLESHOOTING.md)

---

Keep this doc up to date if Hugo paths or workflows change. It should be the one-stop reference for ‚Äúhow do my dotfiles talk to my MS site?‚Äù.***


---

## üìö Dispatcher Technical Reference

This directory contains 12 core AI dispatcher scripts (including `dhp-morphling.sh` and `dhp-finance.sh`) plus 4 advanced orchestration features that provide instant access to specialized AI professionals from the [AI-Staff-HQ](https://github.com/ryan258/AI-Staff-HQ) workforce. Each dispatcher is a high-speed orchestration layer that connects your workflow to the right specialist via OpenRouter API.

**Status:** ‚úÖ 12/12 Core Dispatchers Active + 4 Advanced Features (Phases 1-3, 5-6 Complete)

**Latest Update (February 3, 2026):**

- ‚úÖ All dispatchers support real-time streaming with `--stream` flag
- ‚úÖ Robust error handling via shared library (`dhp-lib.sh`)
- ‚úÖ No more silent failures - API errors reported clearly
- ‚úÖ ~1,500 lines of duplicate code eliminated

---

## Quick Reference

| Dispatcher         | Alias       | Purpose             | Input Method |
| ------------------ | ----------- | ------------------- | ------------ |
| `dhp-tech.sh`      | `tech`      | Technical debugging | stdin        |
| `dhp-creative.sh`  | `creative`  | Story packages      | argument     |
| `dhp-content.sh`   | `content`   | SEO content         | argument     |
| `dhp-strategy.sh`  | `strategy`  | Strategic analysis  | stdin        |
| `dhp-brand.sh`     | `brand`     | Brand positioning   | stdin        |
| `dhp-market.sh`    | `market`    | Market research     | stdin        |
| `dhp-stoic.sh`     | `stoic`     | Stoic coaching      | stdin        |
| `dhp-research.sh`  | `research`  | Knowledge synthesis | stdin        |
| `dhp-narrative.sh` | `narrative` | Story structure     | stdin        |
| `dhp-copy.sh`      | `aicopy`    | Marketing copy      | stdin        |
| `dhp-morphling.sh` | `dhp-morphling` | Universal adaptive dispatcher | argument |
| `dhp-finance.sh`   | `finance`   | Financial strategy  | stdin/arg    |

**Morphling launcher:** `morphling` now points to `bin/morphling.sh` for interactive specialist mode from any directory.

## Advanced Features

| Feature          | Alias        | Purpose                         | Usage    |
| ---------------- | ------------ | ------------------------------- | -------- |
| `dhp-project.sh` | `ai-project` | Multi-specialist orchestration  | argument |
| `dhp-chain.sh`   | `ai-chain`   | Sequential dispatcher chaining  | special  |
| `ai_suggest.sh`  | `ai-suggest` | Context-aware suggestions       | none     |
| `dhp-context.sh` | `ai-context` | Local context injection library | source   |

---

## Technical & Development

### `dhp-tech.sh` (Automation Specialist)

**Purpose:** Debug code, optimize scripts, provide technical analysis

**Input:** Reads from stdin
**Model:** `TECH_MODEL` (default: `moonshotai/kimi-k2:free`)
**Specialist:** `ai-staff-hq/staff/tech/automation-specialist.yaml`

**Usage:**

```bash
# Debug a script
cat broken-script.sh | tech

# Debug with real-time streaming
cat broken-script.sh | tech --stream

# Get optimization advice
echo "How to optimize this bash loop?" | tech

# Analyze error messages
echo "TypeError: undefined is not a function" | tech
```

**Flags:**

- `--stream` - Enable real-time streaming output

**Output:** Bug analysis, fix explanation, corrected code printed to stdout

---

## Creative & Content

### `dhp-creative.sh` (Creative Team)

**Purpose:** Generate complete story packages with beat sheets, characters, sensory details

**Input:** Story idea or logline as argument
**Model:** `CREATIVE_MODEL` (default: `moonshotai/kimi-k2:free`)
**Specialists:** Chief of Staff, Narrative Designer, Creative Strategist, Meditation Instructor
**Output Location:** Configurable via `CREATIVE_OUTPUT_DIR` (default: `~/Projects/creative-writing/`)

**Usage:**

```bash
creative "A lighthouse keeper finds a mysterious artifact"

# With real-time streaming
creative --stream "Astronaut discovers sentient fog on Europa"

# Full command
dhp-creative.sh --stream "Software engineer's AI becomes sentient"
```

**Flags:**

- `--stream` - Enable real-time streaming output

**Output:** Markdown file with complete story package saved to projects directory

---

### `dhp-narrative.sh` (Narrative Designer)

**Purpose:** Story structure analysis, plot development, character arcs

**Input:** Reads from stdin
**Model:** `CREATIVE_MODEL`
**Specialist:** `ai-staff-hq/staff/producers/narrative-designer.yaml`

**Usage:**

```bash
# Analyze story structure
echo "My hero starts weak, gains power, faces dark reflection" | narrative

# With streaming for long analysis
cat story-outline.md | narrative --stream

# Character arc analysis
echo "Character goes from selfish to selfless" | narrative
```

**Flags:**

- `--stream` - Enable real-time streaming output

**Output:** Story structure analysis, plot suggestions, character arc recommendations

---

### `dhp-copy.sh` (Copywriter)

**Purpose:** Sales copy, email sequences, landing pages, conversion-focused messaging

**Input:** Reads from stdin
**Model:** `CREATIVE_MODEL`
**Specialist:** `ai-staff-hq/staff/producers/copywriter.yaml`

**Usage:**

```bash
# Generate sales copy
echo "Product: AI-powered task manager for ADHD" | aicopy

# Email sequence with streaming
echo "Launch sequence for new course on creative writing" | aicopy --stream

# Landing page copy
echo "SaaS tool for content creators - convert visitors" | aicopy
```

**Flags:**

- `--stream` - Enable real-time streaming output

**Output:** Compelling copy with headlines, body, and call-to-action

---

### `dhp-content.sh` (Content Strategy Team)

**Purpose:** SEO-optimized evergreen guides and blog content

**Input:** Topic as argument
**Model:** `CONTENT_MODEL` (default: `moonshotai/kimi-k2:free`)
**Specialists:** Chief of Staff, Market Analyst, Copywriter
**Output Location:** Configurable via `CONTENT_OUTPUT_DIR` (falls back to `$BLOG_DIR/content/guides/`)

**Usage:**

```bash
content "Guide on overcoming creative blocks with AI"

# With streaming for long content
content --stream "Complete guide to stoic philosophy for developers"

# With context injection
dhp-content.sh --context "Guide on productivity with AI"

# Streaming + context
dhp-content.sh --stream --context "Advanced Git workflows"
```

**Flags:**

- `--stream` - Enable real-time streaming output
- `--context` - Include minimal local context (git, top tasks)
- `--full-context` - Include full context (journal, todos, README, git)

**Output:** SEO-optimized Hugo-ready markdown outline with research

---

## Strategy & Analysis

### `dhp-strategy.sh` (Chief of Staff)

**Purpose:** Strategic analysis, insights, patterns, and actionable recommendations

**Input:** Reads from stdin
**Model:** `STRATEGY_MODEL` (defaults to `DEFAULT_MODEL` / `moonshotai/kimi-k2:free`)
**Specialist:** `ai-staff-hq/staff/strategy/chief-of-staff.yaml`

**Usage:**

```bash
# Analyze journal entries
tail -20 ~/.config/dotfiles-data/journal.txt | strategy

# Strategic planning with streaming
echo "Launch AI consulting service - what's the roadmap?" | strategy --stream

# Pattern recognition
cat weekly-metrics.txt | strategy
```

**Flags:**

- `--stream` - Enable real-time streaming output

**Output:** Key insights, strategic recommendations, risks/opportunities

**Integrated with:**

- `journal analyze` (7-day insights)
- `journal mood` (14-day sentiment)
- `journal themes` (30-day patterns)

---

### `dhp-brand.sh` (Brand Builder)

**Purpose:** Brand positioning, voice/tone development, competitive analysis

**Input:** Reads from stdin
**Model:** `BRAND_MODEL` (falls back to `STRATEGY_MODEL`)
**Specialist:** `ai-staff-hq/staff/strategy/brand-builder.yaml`

**Usage:**

```bash
# Brand positioning
echo "Tech blog focused on AI for creative work" | brand

# Voice and tone with streaming
echo "Define brand voice: educational but playful" | brand --stream

# Competitive analysis
echo "Analyze positioning vs. other AI content creators" | brand
```

**Flags:**

- `--stream` - Enable real-time streaming output

**Output:** Brand attributes, voice recommendations, differentiation opportunities, messaging pillars

---

### `dhp-market.sh` (Market Analyst)

**Purpose:** SEO keyword research, trend analysis, audience insights

**Input:** Reads from stdin
**Model:** `STRATEGY_MODEL`
**Specialist:** `ai-staff-hq/staff/strategy/market-analyst.yaml`

**Usage:**

```bash
# SEO research
echo "Keywords for AI productivity tools content" | market

# Trend analysis with streaming
echo "Current trends in AI-assisted creative work" | market --stream

# Audience insights
echo "Who's searching for AI writing assistance?" | market
```

**Flags:**

- `--stream` - Enable real-time streaming output

**Output:** Keyword opportunities, market trends, audience insights, competitive landscape

---

### `dhp-finance.sh` (Financial Strategy)

**Purpose:** Tax and admin strategy (S‚ÄëCorp, R&D credits, Medicare SGA constraints)

**Input:** Reads from stdin or arguments
**Model:** `FINANCE_MODEL` (default: `moonshotai/kimi-k2:free`)
**Usage:**

```bash
# Direct invocation
dhp-finance.sh "S-Corp vs LLC tradeoffs for an R&D lab"

# Unified entry point
dispatch finance "Medicare SGA safe income planning"

# Alias
finance "Medicare SGA safe income planning"
```

**Flags:**

- `--stream` - Enable real-time streaming output

**Output:** Focused financial strategy and administrative checklist

---

## Personal Development

### `dhp-stoic.sh` (Stoic Coach)

**Purpose:** Mindset coaching through stoic principles, reframing challenges

**Input:** Reads from stdin
**Model:** `STRATEGY_MODEL`
**Specialist:** `ai-staff-hq/staff/health-lifestyle/stoic-coach.yaml`

**Usage:**

```bash
# Handle overwhelm
echo "Overwhelmed by too many tasks and perfectionism" | stoic

# Process setbacks with streaming
echo "Project failed after months of work" | stoic --stream

# Daily reflection
echo "Feeling stuck in analysis paralysis" | stoic
```

**Flags:**

- `--stream` - Enable real-time streaming output

**Output:** Stoic reframe, control analysis, practical action, relevant quote

---

### `dhp-research.sh` (Academic Researcher)

**Purpose:** Research organization, source summarization, knowledge synthesis

**Input:** Reads from stdin
**Model:** `STRATEGY_MODEL`
**Specialist:** `ai-staff-hq/staff/strategy/academic-researcher.yaml`

**Usage:**

```bash
# Synthesize research
cat research-notes.md | research

# Organize information with streaming
echo "Summarize key points about AI agents" | research --stream

# Connect concepts
cat multiple-sources.txt | research
```

**Flags:**

- `--stream` - Enable real-time streaming output

**Output:** Key themes, structured organization, connections, next research directions

---

## Universal Adaptive Specialist

### `morphling.sh` (Interactive Morphling Launcher)

**Purpose:** Launch the AI-Staff-HQ Morphling specialist from any working directory

**Input:** Optional query argument, optional stdin, or interactive mode
**Specialist:** `ai-staff-hq/staff/meta/morphling.yaml`

**Usage:**

```bash
# Interactive session
morphling

# One-shot query
morphling "Review this code for security issues"

# Piped one-shot query
cat error.log | morphling
```

---

### `dhp-morphling.sh` (Morphling)

**Purpose:** Universal "shapeshifting" specialist that auto-adapts to any task by analyzing context

**Input:** Task description as argument
**Model:** `MORPHLING_MODEL` (default: `moonshotai/kimi-k2:free`)
**Specialist:** `ai-staff-hq/staff/meta/morphling.yaml`
**Output Location:** `~/Documents/AI_Staff_HQ_Outputs/Morphling/`

**Usage:**

```bash
# Let Morphling analyze context and adapt
dhp-morphling "Review this code for security issues"

# Use in any directory - it gathers context automatically
cd ~/Projects/my-app && dhp-morphling "What should I focus on next?"

# Pipe content for analysis
cat error.log | dhp-morphling "Diagnose this issue"
```

**Context Gathering:**
Morphling automatically gathers:

- Git branch and status (if in a repo)
- Directory structure (depth 2, using `tree` or `fd`)
- Current working directory

**How It Works:**

1. Gathers environmental context (git, directory structure, working dir)
2. Analyzes your request alongside the context
3. Determines the optimal persona/role for the task
4. Shapeshifts into that expert and executes

**Best For:**

- When you're unsure which specialist to use
- General-purpose tasks that span multiple domains
- Quick context-aware assistance in any project

---

## Workflow Integrations

These dispatchers are deeply integrated into daily workflow commands:

### Blog Workflow (`scripts/blog.sh`)

```bash
blog generate <stub-name>  # Uses dhp-content.sh
blog refine <file>          # Uses dhp-content.sh
```

### Todo Integration (`scripts/todo.sh`)

```bash
todo debug <num>            # Uses dhp-tech.sh
todo delegate <num> <type>  # Routes to appropriate dispatcher
```

### Journal Analysis (`scripts/journal.sh`)

```bash
journal analyze             # Uses dhp-strategy.sh
journal mood                # Uses dhp-strategy.sh
journal themes              # Uses dhp-strategy.sh
```

### Daily Automation (Optional)

```bash
# Set in .env:
AI_BRIEFING_ENABLED=true    # Uses dhp-strategy.sh in startday
AI_REFLECTION_ENABLED=true  # Uses dhp-strategy.sh in goodevening
```

---

## Configuration

All dispatchers require:

1. **OpenRouter API Key** in `.env`:

   ```bash
   OPENROUTER_API_KEY=your_key_here
   ```

2. **Model Configuration** in `.env`:

   ```bash
   DEFAULT_MODEL=moonshotai/kimi-k2:free
   TECH_MODEL=moonshotai/kimi-k2:free
   CREATIVE_MODEL=moonshotai/kimi-k2:free
   CONTENT_MODEL=moonshotai/kimi-k2:free
   STRATEGY_MODEL=moonshotai/kimi-k2:free
   BRAND_MODEL=moonshotai/kimi-k2:free   # Optional brand override
   MORPHLING_MODEL=moonshotai/kimi-k2:free
   ```

3. **AI-Staff-HQ Submodule** at `~/dotfiles/ai-staff-hq/`

---

## Error Handling

All dispatchers include:

- ‚úÖ Dependency checks (curl, jq)
- ‚úÖ API key validation
- ‚úÖ Model configuration validation
- ‚úÖ Specialist file existence checks
- ‚úÖ Clear error messages with actionable guidance

---

## Testing

Verify all dispatchers are working:

```bash
bash ~/dotfiles/scripts/dotfiles_check.sh
# Should report: "‚úÖ Found 12/12 dispatchers"
```

Test individual dispatcher:

```bash
echo "Test input" | tech
```

---

## Development

### Adding a New Dispatcher

1. Create script in `bin/dhp-newname.sh`
2. Follow existing pattern (see `dhp-stoic.sh` for simple stdin example)
3. Make executable: `chmod +x bin/dhp-newname.sh`
4. Add to `zsh/aliases.zsh`
5. Update `scripts/dotfiles_check.sh` DISPATCHERS array
6. Test with `dotfiles_check.sh`
7. Document here

### Dispatcher Template

```bash
#!/usr/bin/env bash
set -euo pipefail

DOTFILES_DIR="$HOME/dotfiles"
AI_STAFF_DIR="$DOTFILES_DIR/ai-staff-hq"

if [ -f "$DOTFILES_DIR/.env" ]; then source "$DOTFILES_DIR/.env"; fi

# Validate dependencies and config
if ! command -v curl &> /dev/null || ! command -v jq &> /dev/null; then
    echo "Error: curl and jq required." >&2; exit 1
fi

if [ -z "$OPENROUTER_API_KEY" ]; then
    echo "Error: OPENROUTER_API_KEY not set." >&2; exit 1
fi

MODEL="${YOUR_MODEL}"
if [ -z "$MODEL" ]; then
    echo "Error: Model not configured." >&2; exit 1
fi

STAFF_FILE="$AI_STAFF_DIR/staff/department/specialist.yaml"
if [ ! -f "$STAFF_FILE" ]; then
    echo "Error: Specialist not found at $STAFF_FILE" >&2; exit 1
fi

# Read input
PIPED_CONTENT=$(cat -)
if [ -z "$PIPED_CONTENT" ]; then
    echo "Usage: <input> | $0" >&2; exit 1
fi

echo "Activating 'Specialist Name' via OpenRouter..." >&2
echo "---" >&2

# Build prompt
MASTER_PROMPT=$(cat "$STAFF_FILE")
MASTER_PROMPT+="

--- YOUR REQUEST ---
$PIPED_CONTENT

Provide: [what this specialist should deliver]
"

# Call API
JSON_PAYLOAD=$(jq -n --arg model "$MODEL" --arg prompt "$MASTER_PROMPT" \
    '{model: $model, messages: [{role: "user", content: $prompt}]}')

curl -s -X POST "https://openrouter.ai/api/v1/chat/completions" \
    -H "Authorization: Bearer $OPENROUTER_API_KEY" \
    -H "Content-Type: application/json" \
    -d "$JSON_PAYLOAD" | jq -r '.choices[0].message.content'

echo -e "\n---" >&2
echo "SUCCESS: 'Specialist Name' complete." >&2
```

---

## Advanced Features Documentation

### `dhp-project.sh` - Multi-Specialist Orchestration

**Purpose:** Coordinate multiple AI specialists for complex projects

**Input:** Project description as argument
**Model:** Uses multiple models across specialists
**Specialists:** Market Analyst, Brand Builder, Chief of Staff, Content Specialist, Copywriter
**Output:** Comprehensive markdown project brief to stdout

**Usage:**

```bash
dhp-project "Launch new blog series on AI productivity"

# Or use alias
ai-project "Create comprehensive onboarding program"

# Save output to file
dhp-project "New product launch strategy" > project-brief.md
```

**Workflow:**

1. **Market Analyst** - Researches topic, identifies opportunities
2. **Brand Builder** - Defines positioning and messaging
3. **Chief of Staff** - Creates strategic plan and timeline
4. **Content Specialist** - Develops content strategy
5. **Copywriter** - Generates promotional copy

**Output:** Complete project brief with all phases integrated

---

### `dhp-chain.sh` - Dispatcher Chaining

**Purpose:** Sequential processing through multiple AI specialists

**Input:** Special syntax: `dispatcher1 dispatcher2 [dispatcher3...] -- "input"`
**Dispatchers:** Any combination of available dispatchers
**Output:** Final result after all processing steps

**Usage:**

```bash
# Story generation ‚Üí structure analysis ‚Üí marketing hook
dhp-chain creative narrative aicopy -- "lighthouse keeper finds mysterious artifact"

# Market research ‚Üí brand strategy ‚Üí content plan
dhp-chain market brand content -- "AI productivity tools for developers"

# Technical analysis ‚Üí strategic review
dhp-chain tech strategy -- "optimize database query performance"

# Save final output
dhp-chain creative narrative -- "story idea" --save story-brief.md
```

**Available Dispatchers:**

- tech, creative, content, strategy, brand, market, stoic, research, narrative, aicopy

**Features:**

- Progress display after each step
- Intermediate outputs shown to stderr
- Final output to stdout
- Optional `--save <file>` flag

---

### `ai_suggest.sh` - Context-Aware Suggestions

**Purpose:** Analyze current environment and suggest relevant AI dispatchers

**Input:** None (reads environment automatically)
**Output:** Contextual suggestions to stdout

**Usage:**

```bash
ai-suggest
```

**Context Analysis:**

- Current directory and project type
- Git repository status and recent commits
- Active todo items and priorities
- Recent journal entries (last 3 days)
- Health signals: latest daily energy score from `health.sh`
- Medication adherence: overdue doses flagged via `meds.sh check`
- Time of day (morning/evening suggestions)

**Example Output:**

```
üìç Your Current Context:
Current directory: /Users/you/blog
Git repository: personal-blog
Recent commits:
  abc123 Update content strategy

üí° Suggested Dispatchers:
  üìù **Content Dispatcher**: Generate or refine blog content
     blog generate <stub-name>
     blog refine <file>

  üìä **Journal Analysis**: Get insights from your journal
     journal analyze
```

---

### `dhp-context.sh` - Local Context Injection

**Purpose:** Gather and inject local context into AI dispatcher prompts

**Input:** Source this library to access context functions
**Output:** Context data as text
**Usage:** Function library (not direct execution)

**Main Functions:**

**`gather_context [--minimal|--full]`**
Collects all relevant local context:

```bash
source dhp-context.sh
gather_context --minimal    # Git + top 3 tasks
gather_context --full       # Everything (journal, todos, README, git)
```

**`get_git_context [commit_count]`**
Repository and commit history:

```bash
get_git_context 10  # Last 10 commits
```

**`get_recent_journal [days]`**
Recent journal entries:

```bash
get_recent_journal 7  # Last 7 days
```

**`get_active_todos [limit]`**
Active task list:

```bash
get_active_todos 5  # Top 5 tasks
```

**`get_project_readme`**
Project README (first 50 lines):

```bash
get_project_readme
```

**Context Injection in Dispatchers:**

Example: `dhp-content.sh` with context flags:

```bash
# Minimal context (git status, top tasks)
dhp-content --context "Guide on productivity with AI"

# Full context (journal, todos, README, git history)
dhp-content --full-context "Comprehensive guide topic"
```

**Benefits:**

- Prevents duplicate content creation
- Aligns AI output with current work
- Includes relevant project context automatically
- References recent tasks and journal themes

---

## Spec-Driven Workflow

For complex dispatcher tasks, use the `spec` command to open structured templates that guide you through providing comprehensive input to AI specialists.

### Using Structured Specs

```bash
spec tech      # Opens tech-spec.txt template in VS Code
spec creative  # Opens creative-spec.txt template
spec content   # Opens content-spec.txt template
spec strategy  # Opens strategy-spec.txt template
spec market    # Opens market-spec.txt template
spec research  # Opens research-spec.txt template
spec stoic     # Opens stoic-spec.txt template
```

### Workflow

1. Run `spec <dispatcher>` (e.g., `spec tech`)
2. Your editor (VS Code) opens with a pre-filled template
3. Fill in the template sections with your requirements
4. Save and close the file
5. The spec automatically pipes to the appropriate dispatcher
6. Completed spec saved to `~/.config/dotfiles-data/specs/` for reuse

### Available Templates

Each dispatcher has a custom-tailored template:

**`tech-spec.txt`** - Technical debugging and analysis

- Issue description, expected vs. current behavior
- Environment context and recent changes
- Areas to investigate, output format

**`creative-spec.txt`** - Creative writing projects

- Story type, length, setting, protagonist
- Core conflict, tone, structure
- Elements to avoid

**`content-spec.txt`** - Content creation

- Title/topic, target audience, length
- Structure (opening, body, conclusion)
- SEO keywords, tone, inclusions

**`strategy-spec.txt`** - Strategic analysis

- Current state, decision/question
- Constraints (time, resources, requirements)
- Options to evaluate, criteria

**`market-spec.txt`** - Market research

- Research focus, key questions
- Comparison baseline, use case
- Depth required

**`research-spec.txt`** - Knowledge synthesis

- Source material, analysis scope
- Depth required, output format, tone

**`stoic-spec.txt`** - Stoic coaching

- Situation, emotional state
- What you've tried, reflection questions
- Expected output type

**`dispatcher-spec-template.txt`** - Generic fallback

- Used for any dispatcher without a specific template

### Reusing Specs

All completed specs are automatically saved with timestamps:

```bash
# List saved specs
ls ~/.config/dotfiles-data/specs/

# Reuse a previous spec
cat ~/.config/dotfiles-data/specs/20251110-100534-tech.txt | tech

# Edit and reuse
code ~/.config/dotfiles-data/specs/20251110-100534-creative.txt
# Make changes, then pipe to dispatcher
```

### Multi-line Input Methods

If you prefer not to use the spec templates:

**Heredoc (recommended for multi-line input):**

```bash
tech <<EOF
Your multi-line
spec here
EOF
```

**Backslash continuation:**

```bash
tech "Line 1 \
Line 2 \
Line 3"
```

**Direct piping:**

```bash
echo "Quick question or analysis request" | tech
```

### Configuration

The spec workflow uses your configured editor:

```bash
# Set in ~/.zshrc
export EDITOR="code --wait"   # VS Code (default)
export EDITOR="vim"            # Vim
export EDITOR="nano"           # Nano
```

### Benefits

- **Structured thinking** - Templates guide comprehensive input
- **Reusability** - Save and reuse successful spec patterns
- **Consistency** - Same format every time improves AI output
- **Documentation** - Archived specs serve as project history
- **Less context switching** - Editor + dispatcher in one workflow

---

---

## Swipe Logging

### `swipe.sh` - Output Logging Wrapper

**Purpose:** Wrap any command and automatically log its output to a swipe file

**Usage:**

```bash
# Log any command output
swipe tech "Summarize today's wins"
swipe creative "Story idea"

# Works with any dispatcher alias
swipe market "Analyze competitors"
```

**Configuration:**

```bash
# Enable in .env
SWIPE_LOG_ENABLED=true
SWIPE_LOG_FILE=~/Documents/swipe.md  # Optional, defaults to this

# Disable logging (commands still run, just no logging)
SWIPE_LOG_ENABLED=false
```

**Output Format:** Commands are logged to the swipe file as timestamped markdown entries with the command and its output preserved in code blocks.

---

## Resources

- **AI-Staff-HQ Repository:** https://github.com/ryan258/AI-Staff-HQ
- **OpenRouter Dashboard:** https://openrouter.ai/
- **Implementation Roadmap:** `~/dotfiles/ROADMAP.md`
- **Change History:** `~/dotfiles/CHANGELOG.md`
- **Main Documentation:** `~/dotfiles/README.md`

---

**Last Updated:** November 10, 2025
**Status:** Production-ready, 12 dispatchers + 4 advanced features + spec workflow operational
**Phase:** 1, 2, 3, 5, 6 Complete (Infrastructure, Workflow Integration, Dispatcher Expansion, Advanced Features, Model Configuration + Spec System)
